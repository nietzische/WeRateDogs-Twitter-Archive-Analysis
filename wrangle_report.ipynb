{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "Three different pieces of data required gathering using different methods for this project. These included:\n",
    "\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)\n",
    " \n",
    "      * This archive was provided by Udacity, and was readily available for download.\n",
    "      \n",
    "      \n",
    " \n",
    "2. Using the Requests library to download the tweet image prediction (image_predictions.tsv)\n",
    "\n",
    "    * Assigning a provided url to use in get() method\n",
    "    * Using the get() method to send a GET request to the url page\n",
    "    * Checking the status code of the request to confirm successful download\n",
    "    * Writing the response to an output file that matches a tab delimited format - image_predictions.tsv\n",
    "    * Loading the file into a pandas dataframe\n",
    "    \n",
    "    \n",
    "    \n",
    "3. Uploading and reading additional Tweet data from tweet_json.txt file\n",
    "\n",
    "    * The contents of the file were stored in a json format. The data was read line by line to obtain additional information about the tweets in the twitter-archive. The information obtained included:\n",
    "            1. Retweet counts\n",
    "            2. Favorite counts\n",
    "            3. Time of creation of each tweet\n",
    "        \n",
    "       \n",
    "       \n",
    "The three pieces of data gathered now included:\n",
    "\n",
    "1. `Twitter-archive-enhanced.csv`\n",
    "2. `Image_predictions.tsv`\n",
    "3. `Tweet_json.txt`\n",
    "\n",
    "They were all loaded into separate pandas dataframes:\n",
    "\n",
    "1. `twitter_archive`\n",
    "2. `image_predictions`\n",
    "3. `tweet_json_data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This involved both visual and programmatic assessment.\n",
    "The following key points acted as guidelines during assessment of the data:\n",
    "\n",
    "* Only original ratings (no retweets) that have images are required. Not all are dog ratings and some are retweets.\n",
    "* The requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps were followed during assessment:\n",
    "\n",
    "   `twitter_archive`\n",
    "    \n",
    "1. Describing each column in the table to gain awareness of all the variables in each table\n",
    "2.\n",
    "3. Checking the distribution of missing values using the `missingno`library to detect missing data\n",
    "4. Checking for duplicated records in each table using duplicated() function\n",
    "5. Checking the value counts in the rating denominator and rating numerator columns\n",
    "6. Checking to see which entries had values of 0 in both rating numerator and rating denominator columns\n",
    "7. Finding entries that were labelled as 'None' in the name column of the `twitter_archive`.\n",
    "8. Going through the text entries of records whose name column matched 'None', to assess whether names were present in the text and had been left out\n",
    "9. Checking the value counts of the dog stages columns, followed by checking their sum totals\n",
    "10. Checking the entries in the source column\n",
    "\n",
    "`image_predictions`\n",
    "    \n",
    "1. Displaying the table\n",
    "2. Describing each column in the table to gain awareness of all the variables in each table\n",
    "3. Checking the distribution of missing values using the `missingno`library to detect missing data\n",
    "4. Checking for duplicated records in each table using duplicated() function\n",
    "3. Using the describe() function to check the distribution of the confidence columns\n",
    "4. Checking the prediction with a confidence of 1\n",
    "5. Checking the value counts of p1_dog, p2_dog, p3_dog columns\n",
    "\n",
    "`tweet_json_data`\n",
    "    \n",
    "1. Displaying the table\n",
    "2. Describing each column in the table to gain awareness of all the variables in each table\n",
    "3. Using `.info()` to assess the columns and their datatypes\n",
    "4. Checking for duplicates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "\n",
    "#### *Twitter Archive Table*\n",
    "1. Remove the retweets and replies included in the Twitter archive table\n",
    "* Some rating denominators have the value of 0 or greater than 10\n",
    "* Timestamp is an object datatype instead of datetime\n",
    "* Text column contains both text from the tweet and a short version of the tweet status url\n",
    "* Source columns contains the text and and a url\n",
    "* Missing values in the 'expanded_urls' column\n",
    "* There are missing names labelled a 'None' in the name column\n",
    "* Missing counts in the dog stage category columns (doggo, floofer, pupper, puppo)\n",
    "* Twitter_archive table contains ratings that lack images present in the image predictions table\n",
    "* Image_pred_clean table is missing a prediction column to determine whether the image is of a dog or not, so as to determine true positives and false negatives of the neural network\n",
    "\n",
    "\n",
    "#### *Image Predictions Table*\n",
    "11. Create a dog breed column containing the prediction with the highest confidence\n",
    "* Create a dog breed column containing the prediction with the highest confidence\n",
    "\n",
    "#### *Tweet json data Table*\n",
    "13. created_at column is not in the datetime datatype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness issues\n",
    "#### *Twitter_archive Table*\n",
    "1. There are four columns that represent the same type of data, the dog category is represented in the doggo, floofer, pupper and puppo columns\n",
    "\n",
    "####  *Image_prediction table\n",
    "2. Drop redundant columns from the image predictions table\n",
    "\n",
    "#### *Tweet_json_data* Table*\n",
    "3. This data is separate from the other tweet data in the twitter_archive table\n",
    "4. Merge Twitter archive table with Tweet json data table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made a copy of each table for the cleaning stage\n",
    "\n",
    "`twitter_archive`\n",
    " \n",
    "1. Removed the retweets and replies included in the Twitter archive table\n",
    "      * Identifying and removing rows that contain observations for 'in_reply_to_status' and 'retweet_status_id'\n",
    "      * Droping columns that refer to replies and retweets in the table\n",
    "      \n",
    "    \n",
    "2. Corrected some rating denominators that had a value of 0 or greater than 10\n",
    "      * Created a function to replace values that are greater or less than 10 with 10\n",
    "      \n",
    "    \n",
    "3. Changed the Timestamp object datatype to datetime\n",
    "      * Applied pandas datetime function to Timestamp column\n",
    "      \n",
    "    \n",
    "4. Removed the short version of the tweet status url from the text column that contains both text and the url\n",
    "      * Wrote a function to split the text from the url using .split() and return only the text portion\n",
    "      * Applied the function to the text column using .apply()\n",
    "      \n",
    "      \n",
    "5. Obtained the tweet source from the source url in the source column\n",
    "      * Wrote a function to extract the source of the tweet embedded in the url and applied it to the source column using .apply()\n",
    "      \n",
    "    \n",
    "6. Handled the missing data in the expanded_url column\n",
    "      * The missing values were replace with \"None\" using the pandas fillna() function \n",
    "      \n",
    "      \n",
    "7. Handled the missing names labelled as 'None' in the name column\n",
    "      * No action was performed\n",
    "      \n",
    "      \n",
    "8. Handled missing counts in the dog stage category columns (doggo, floofer, pupper, puppo)\n",
    "      * No action was peformed\n",
    "      \n",
    "      \n",
    "9. Removed twitter_archive table ratings that lacked images present in the image_predictions table\n",
    "      * Removed the ratings in the twitter_archive_clean table that did not have a corresponding tweet ID in the image_predictions_clean_table\n",
    "    \n",
    "`image_predictions`\n",
    "\n",
    "10. Added a prediction column to determine whether the image is of a dog or not, so as to determine true positives and false negatives of the neural network.\n",
    "    * Wrote a function that checked p1_dog, p2_dog and p3_dog boolean values to classify an image as 'dog' or 'not_dog'\n",
    "    * Created a dog prediction column to show whether the neural network labelled the picture as a 'dog' or 'not_dog'\n",
    "    \n",
    "    \n",
    "11. Created a dog breed column containing the prediction with the highest confidence\n",
    "\n",
    "    *  Determined breed by checking the p1, p2, and p3 breed predictions with the highest confidence among the three available predictions by the neural network\n",
    "    \n",
    "`tweet_json_data`\n",
    "12. Changed the created_at column datatype to datetime datatype\n",
    "\n",
    "\n",
    "13. Merged the four columns that represent the same type of data, the dog category is represented in the doggo, floofer, pupper and puppo columns.\n",
    "\n",
    "    * Assigned the values in the four different columns to one new column 'dog_stage'\n",
    "    * Dropped the redundant columns from the twitter archive table\n",
    "    \n",
    "    \n",
    "14. Dropped redundant columns from the image predictions table : 'img_num','p1','p1_dog','p2','p2_dog','p3','p3_dog'\n",
    "\n",
    "\n",
    "15. Merged Twitter archive table with Tweet json data table on tweet ID's"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
